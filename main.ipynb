{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cupy as cp\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Función de activación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + cp.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    return x * (1 - x)\n",
    "\n",
    "def softmax(z):#z: vector resultante antes de funcion de activación en la última capa\n",
    "    exp_z = cp.exp(z - cp.max(z, axis=1, keepdims=True))  \n",
    "    return exp_z / cp.sum(exp_z, axis=1, keepdims=True)#retorna las probabilidades de las posibles clases\n",
    "\n",
    "#mide la diferencia entre distribucion de prob. creada por softmax y los targets reales\n",
    "def cross_entropy_loss(predictions, targets):\n",
    "    return -cp.sum(targets * cp.log(predictions + 1e-9)) / targets.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoder que cambia el formato de labels tal que coincida con las predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(y, num_classes):\n",
    "    if y.ndim > 1:  # Flatten the array if necessary\n",
    "        y = y.flatten()\n",
    "        \n",
    "    one_hot_labels = cp.zeros((y.shape[0], num_classes))\n",
    "    one_hot_labels[cp.arange(y.shape[0]), y] = 1\n",
    "    return one_hot_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clase MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MultiLayerNetwork:\n",
    "    def __init__(self, layer_sizes):\n",
    "        self.layer_sizes = layer_sizes\n",
    "        self.weights = []\n",
    "        self.biases = []\n",
    "\n",
    "        # Initialize weights and biases for each layer\n",
    "        for i in range(len(layer_sizes) - 1):\n",
    "            weight = cp.random.randn(layer_sizes[i], layer_sizes[i + 1]) * cp.sqrt(2. / layer_sizes[i])\n",
    "            bias = cp.zeros((1, layer_sizes[i + 1]))\n",
    "            self.weights.append(weight)\n",
    "            self.biases.append(bias)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        self.activations = [inputs]\n",
    "        a = inputs\n",
    "\n",
    "        for i in range(len(self.weights) - 1):\n",
    "            z = cp.dot(a, self.weights[i]) + self.biases[i]\n",
    "            a = sigmoid(z)\n",
    "            self.activations.append(a)\n",
    "\n",
    "        # Output uses softmax for multiclass classification\n",
    "        z = cp.dot(a, self.weights[-1]) + self.biases[-1]\n",
    "        a = softmax(z)\n",
    "        self.activations.append(a)\n",
    "        return a\n",
    "\n",
    "    def predict(self, inputs):\n",
    "        inputs = cp.array(inputs, ndmin=2)\n",
    "        a = inputs\n",
    "\n",
    "        for i in range(len(self.weights) - 1):\n",
    "            z = cp.dot(a, self.weights[i]) + self.biases[i]\n",
    "            a = sigmoid(z)\n",
    "        \n",
    "        # Output with softmax\n",
    "        z = cp.dot(a, self.weights[-1]) + self.biases[-1]\n",
    "        a = softmax(z)\n",
    "\n",
    "        return a\n",
    "\n",
    "    def backward(self, targets, learning_rate):\n",
    "        m = targets.shape[0]  # number of training examples\n",
    "        delta_weights = [0] * len(self.weights)\n",
    "        delta_biases = [0] * len(self.biases)\n",
    "\n",
    "        # Calculate the initial error (difference between prediction and target for the output layer)\n",
    "        error = self.activations[-1] - targets\n",
    "\n",
    "        for i in reversed(range(len(self.weights))):\n",
    "            # Calculate the delta for the current layer\n",
    "            delta = error\n",
    "            delta_weights[i] = cp.dot(self.activations[i].T, delta) / m\n",
    "            delta_biases[i] = cp.sum(delta, axis=0, keepdims=True) / m\n",
    "\n",
    "            if i != 0:\n",
    "                # Propagate the error to the previous layer\n",
    "                error = cp.dot(delta, self.weights[i].T) * sigmoid_derivative(self.activations[i])\n",
    "\n",
    "            # Update weights and biases\n",
    "            self.weights[i] -= learning_rate * delta_weights[i]\n",
    "            self.biases[i] -= learning_rate * delta_biases[i]\n",
    "\n",
    "            \n",
    "    def train(self, inputs, targets, epochs, learning_rate):\n",
    "        targets = one_hot(targets, 10)\n",
    "\n",
    "        errors = []\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            predictions = self.forward(inputs)\n",
    "            error = cross_entropy_loss(predictions, targets)\n",
    "            self.backward(targets, learning_rate)\n",
    "            errors.append(error)\n",
    "            \n",
    "            if epoch % 10 == 0:\n",
    "                print(f'Epoch {epoch}, Error: {error}')\n",
    "\n",
    "        return errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10155, 3074)\n",
      "(10155, 3072)\n",
      "(10155, 1)\n"
     ]
    }
   ],
   "source": [
    "#Obtener datos (estoy usando pd porque anda considerablemente más rápido que np)\n",
    "train_data = pd.read_csv(r'C:/Users/kueru/Documents/VSCode/semestre_9/Deep_Learning/T2/train_data_2.csv')\n",
    "train_data = train_data.to_numpy()\n",
    "    \n",
    "#Cortar en features y labales\n",
    "train_samples = train_data.shape[0]\n",
    "features = train_data[:train_samples, 1:-1]  # Features for training    \n",
    "labels = train_data[:train_samples, -1]  #Labels for training\n",
    "\n",
    "labels = labels.reshape(-1, 1)  # Reshape to (299, 1)\n",
    "\n",
    "X_train = cp.array(features)\n",
    "y_train = cp.array(labels).flatten()\n",
    "\n",
    "print(train_data.shape)\n",
    "print(features.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Error: 2.5068105629092963\n",
      "Epoch 10, Error: 2.28947607864776\n",
      "Epoch 20, Error: 2.2827386220391017\n",
      "Epoch 30, Error: 2.277174301808653\n",
      "Epoch 40, Error: 2.2720083767745565\n",
      "Epoch 50, Error: 2.266968359081273\n",
      "Epoch 60, Error: 2.2618555014493555\n",
      "Epoch 70, Error: 2.256966304416771\n",
      "Epoch 80, Error: 2.2516349427355724\n",
      "Epoch 90, Error: 2.245993515141124\n",
      "Epoch 100, Error: 2.240669595078174\n",
      "Epoch 110, Error: 2.2348192600822943\n",
      "Epoch 120, Error: 2.229231993656745\n",
      "Epoch 130, Error: 2.2232739632544956\n",
      "Epoch 140, Error: 2.216925876907649\n",
      "Epoch 150, Error: 2.2106246246245465\n",
      "Epoch 160, Error: 2.2035434754232464\n",
      "Epoch 170, Error: 2.1967659979894103\n",
      "Epoch 180, Error: 2.1894546251764124\n",
      "Epoch 190, Error: 2.182251496872506\n",
      "Epoch 200, Error: 2.1735932196188923\n",
      "Epoch 210, Error: 2.1652786408842113\n",
      "Epoch 220, Error: 2.1569509791065067\n",
      "Epoch 230, Error: 2.1479042233422474\n",
      "Epoch 240, Error: 2.1408255575088866\n",
      "Epoch 250, Error: 2.1314696119209025\n",
      "Epoch 260, Error: 2.1217412437361793\n",
      "Epoch 270, Error: 2.1134909894104807\n",
      "Epoch 280, Error: 2.1050803807785052\n",
      "Epoch 290, Error: 2.094628169546649\n",
      "Test Accuracy: 0.31413096996553425\n"
     ]
    }
   ],
   "source": [
    "num_classes = 10\n",
    "input_size = 3072\n",
    "hidden_layers = [256,256,256]  # Tamaños de las capas ocultas\n",
    "output_size = 10\n",
    "layer_sizes = [input_size] + hidden_layers + [output_size]\n",
    "\n",
    "model = MultiLayerNetwork(layer_sizes)\n",
    "epochs = 300\n",
    "learning_rate = 0.05\n",
    "\n",
    "errors = model.train(X_train, y_train, epochs, learning_rate)\n",
    "#Evaluar\n",
    "predictions = model.predict(X_train)\n",
    "accuracy = cp.mean(predictions.argmax(axis=1) == y_train)\n",
    "print(f'Test Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Búsqueda de parámetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid Searh para ajustar complejitud de 1 capa oculta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer size: 1\n",
      "[3072, 1, 10]\n",
      "Epoch 0, Error: 2.302621414426933\n",
      "Epoch 10, Error: 2.3025529936149853\n",
      "Epoch 20, Error: 2.302498165861214\n",
      "Epoch 30, Error: 2.302448581355747\n",
      "Epoch 40, Error: 2.3024037301658726\n",
      "Epoch 50, Error: 2.3023631576199195\n",
      "Epoch 60, Error: 2.302326454222536\n",
      "Epoch 70, Error: 2.302293250202761\n",
      "Epoch 80, Error: 2.3022632113558354\n",
      "Epoch 90, Error: 2.302236035506209\n",
      "Epoch 100, Error: 2.302211449387694\n",
      "Epoch 110, Error: 2.302189205853871\n",
      "Epoch 120, Error: 2.30216908136942\n",
      "Epoch 130, Error: 2.3021508737480465\n",
      "Epoch 140, Error: 2.3021344001100186\n",
      "Epoch 150, Error: 2.302119495036605\n",
      "Epoch 160, Error: 2.3021060089017698\n",
      "Epoch 170, Error: 2.3020938063636947\n",
      "Epoch 180, Error: 2.302082765000622\n",
      "Epoch 190, Error: 2.3020727740770814\n",
      "Test Accuracy: 0.1069423929098966\n",
      "\n",
      "layer size: 10\n",
      "[3072, 10, 10]\n",
      "Epoch 0, Error: 2.579213115582387\n",
      "Epoch 10, Error: 2.3516751832167127\n",
      "Epoch 20, Error: 2.333705394466311\n",
      "Epoch 30, Error: 2.322258709739571\n",
      "Epoch 40, Error: 2.314787074289977\n",
      "Epoch 50, Error: 2.3099065153749825\n",
      "Epoch 60, Error: 2.3068093620290826\n",
      "Epoch 70, Error: 2.3048376121890515\n",
      "Epoch 80, Error: 2.30355701515815\n",
      "Epoch 90, Error: 2.3021764050934914\n",
      "Epoch 100, Error: 2.3025496567828765\n",
      "Epoch 110, Error: 2.3022545787922755\n",
      "Epoch 120, Error: 2.302072624960121\n",
      "Epoch 130, Error: 2.3019612215688063\n",
      "Epoch 140, Error: 2.301893341745262\n",
      "Epoch 150, Error: 2.3018519938550175\n",
      "Epoch 160, Error: 2.301826835675281\n",
      "Epoch 170, Error: 2.3018115331431632\n",
      "Epoch 180, Error: 2.3018022173661676\n",
      "Epoch 190, Error: 2.301796532110569\n",
      "Test Accuracy: 0.10674544559330379\n",
      "\n",
      "layer size: 100\n",
      "[3072, 100, 10]\n",
      "Epoch 0, Error: 2.4679771701467055\n",
      "Epoch 10, Error: 2.239840387715534\n",
      "Epoch 20, Error: 2.1792798106556077\n",
      "Epoch 30, Error: 2.1735837168593535\n",
      "Epoch 40, Error: 2.13901838029953\n",
      "Epoch 50, Error: 2.1058693634972276\n",
      "Epoch 60, Error: 2.11115910025999\n",
      "Epoch 70, Error: 2.075914006976682\n",
      "Epoch 80, Error: 2.0777553072163424\n",
      "Epoch 90, Error: 2.054989200590509\n",
      "Epoch 100, Error: 2.0453986723303115\n",
      "Epoch 110, Error: 2.0223191607306763\n",
      "Epoch 120, Error: 2.0360489231379284\n",
      "Epoch 130, Error: 2.062887127210393\n",
      "Epoch 140, Error: 1.974741568616573\n",
      "Epoch 150, Error: 1.9866385928220927\n",
      "Epoch 160, Error: 2.0199023926393997\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(layer_sizes)\n\u001b[0;32m     11\u001b[0m model \u001b[38;5;241m=\u001b[39m MultiLayerNetwork(layer_sizes)\n\u001b[1;32m---> 12\u001b[0m errors \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m#Evaluar\u001b[39;00m\n\u001b[0;32m     15\u001b[0m predictions \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_train)\n",
      "Cell \u001b[1;32mIn[11], line 78\u001b[0m, in \u001b[0;36mMultiLayerNetwork.train\u001b[1;34m(self, inputs, targets, epochs, learning_rate)\u001b[0m\n\u001b[0;32m     75\u001b[0m     errors\u001b[38;5;241m.\u001b[39mappend(error)\n\u001b[0;32m     77\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m epoch \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m10\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m---> 78\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Error: \u001b[39m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43merror\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m errors\n",
      "File \u001b[1;32mcupy\\_core\\core.pyx:1744\u001b[0m, in \u001b[0;36mcupy._core.core._ndarray_base.__format__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "epochs = 200\n",
    "layer_sizes = [input_size] + hidden_layers + [output_size]\n",
    "lr = 0.05\n",
    "for i in range(0, 5):  # Cambia el 5 por el número de potencias de 10 que desees\n",
    "    val = pow(10, i)\n",
    "    hidden_layers = [val]  # Tamaños de las capas ocultas\n",
    "    print(f\"layer size: {val}\")\n",
    "    layer_sizes = [input_size] + hidden_layers + [output_size]\n",
    "    print(layer_sizes)\n",
    "\n",
    "    model = MultiLayerNetwork(layer_sizes)\n",
    "    errors = model.train(X_train, y_train, epochs, lr)\n",
    "\n",
    "    #Evaluar\n",
    "    predictions = model.predict(X_train)\n",
    "    accuracy = cp.mean(predictions.argmax(axis=1) == y_train)\n",
    "    print(f'Test Accuracy: {accuracy}')\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search para ajustar numero de capas ocultas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden layers: [256]\n",
      "Epoch 0, Error: 105.86025886841283\n",
      "Test Accuracy: 0.09698996655518395\n",
      "\n",
      "hidden layers: [256, 256]\n",
      "Epoch 0, Error: 108.85456644116445\n",
      "Test Accuracy: 0.14046822742474915\n",
      "\n",
      "hidden layers: [256, 256, 256]\n",
      "Epoch 0, Error: 105.7057006341719\n",
      "Test Accuracy: 0.14046822742474915\n",
      "\n",
      "hidden layers: [256, 256, 256, 256]\n",
      "Epoch 0, Error: 110.30727016766471\n",
      "Test Accuracy: 0.14046822742474915\n",
      "\n",
      "hidden layers: [256, 256, 256, 256, 256]\n",
      "Epoch 0, Error: 125.7849884262953\n",
      "Test Accuracy: 0.14046822742474915\n",
      "\n",
      "hidden layers: [256, 256, 256, 256, 256, 256]\n",
      "Epoch 0, Error: 111.10845764177878\n",
      "Test Accuracy: 0.14046822742474915\n",
      "\n",
      "hidden layers: [256, 256, 256, 256, 256, 256, 256]\n",
      "Epoch 0, Error: 106.9112295635407\n",
      "Test Accuracy: 0.14046822742474915\n",
      "\n",
      "hidden layers: [256, 256, 256, 256, 256, 256, 256, 256]\n",
      "Epoch 0, Error: 107.25215446902249\n",
      "Test Accuracy: 0.14046822742474915\n",
      "\n",
      "hidden layers: [256, 256, 256, 256, 256, 256, 256, 256, 256]\n",
      "Epoch 0, Error: 105.26643352242563\n",
      "Test Accuracy: 0.14046822742474915\n",
      "\n",
      "hidden layers: [256, 256, 256, 256, 256, 256, 256, 256, 256, 256]\n",
      "Epoch 0, Error: 120.37974780141502\n",
      "Test Accuracy: 0.14046822742474915\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "num_classes = 10\n",
    "input_size = 3072\n",
    "hidden_layer_size = 256\n",
    "hidden_layers = []  # Tamaños de las capas ocultas\n",
    "output_size = 10\n",
    "layer_sizes = [input_size] + hidden_layers + [output_size]\n",
    "epochs = 100\n",
    "lr = 0.0001\n",
    "\n",
    "for i in range(0, 10):  # Cambia el 5 por el número de potencias de 10 que desees\n",
    "    hidden_layers.append(hidden_layer_size)  # Tamaños de las capas ocultas\n",
    "    print(f\"hidden layers: {hidden_layers}\")\n",
    "    layer_sizes = [input_size] + hidden_layers + [output_size]\n",
    "\n",
    "    model = MultiLayerNetwork(layer_sizes)\n",
    "    errors = model.train(X_train, y_train, epochs, lr)\n",
    "\n",
    "    #Evaluar\n",
    "    predictions = model.predict(X_train)\n",
    "    accuracy = cp.mean(predictions.argmax(axis=1) == y_train)\n",
    "    print(f'Test Accuracy: {accuracy}')\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo entrenado con parámetros encontrados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularizaciones:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dropout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MultiLayerNetwork_Dropout:\n",
    "    def __init__(self, layer_sizes, dropout_rate=0.5):\n",
    "        self.layer_sizes = layer_sizes\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.weights = []\n",
    "        self.biases = []\n",
    "        self.dropout_masks = []\n",
    "\n",
    "        # Initialize weights and biases for each layer\n",
    "        for i in range(len(layer_sizes) - 1):\n",
    "            weight = cp.random.randn(layer_sizes[i], layer_sizes[i + 1]) * cp.sqrt(2. / layer_sizes[i])\n",
    "            bias = cp.zeros((1, layer_sizes[i + 1]))\n",
    "            self.weights.append(weight)\n",
    "            self.biases.append(bias)\n",
    "            # Initialize dropout mask\n",
    "            self.dropout_masks.append(None)\n",
    "\n",
    "    def forward(self, inputs, training=True):\n",
    "        self.activations = [inputs]\n",
    "        a = inputs\n",
    "\n",
    "        for i in range(len(self.weights) - 1):\n",
    "            z = cp.dot(a, self.weights[i]) + self.biases[i]\n",
    "            a = sigmoid(z)\n",
    "\n",
    "            if training:\n",
    "                # Apply dropout\n",
    "                dropout_mask = (cp.random.rand(*a.shape) > self.dropout_rate) / (1.0 - self.dropout_rate)\n",
    "                a *= dropout_mask\n",
    "                self.dropout_masks[i] = dropout_mask\n",
    "\n",
    "            self.activations.append(a)\n",
    "\n",
    "        # Output uses softmax for multiclass classification\n",
    "        z = cp.dot(a, self.weights[-1]) + self.biases[-1]\n",
    "        a = softmax(z)\n",
    "        self.activations.append(a)\n",
    "        return a\n",
    "\n",
    "    def predict(self, inputs):\n",
    "        inputs = cp.array(inputs, ndmin=2)\n",
    "        return self.forward(inputs, training=False)\n",
    "\n",
    "    def backward(self, targets, learning_rate):\n",
    "        m = targets.shape[0]  # number of training examples\n",
    "        delta_weights = [0] * len(self.weights)\n",
    "        delta_biases = [0] * len(self.biases)\n",
    "\n",
    "        # Calculate the initial error (difference between prediction and target for the output layer)\n",
    "        error = self.activations[-1] - targets\n",
    "\n",
    "        for i in reversed(range(len(self.weights))):\n",
    "            # Calculate the delta for the current layer\n",
    "            delta = error\n",
    "            delta_weights[i] = cp.dot(self.activations[i].T, delta) / m\n",
    "            delta_biases[i] = cp.sum(delta, axis=0, keepdims=True) / m\n",
    "\n",
    "            if i != 0:\n",
    "                # Propagate the error to the previous layer\n",
    "                error = cp.dot(delta, self.weights[i].T) * sigmoid_derivative(self.activations[i])\n",
    "                if self.dropout_masks[i-1] is not None:\n",
    "                    error *= self.dropout_masks[i-1]\n",
    "\n",
    "            # Update weights and biases\n",
    "            self.weights[i] -= learning_rate * delta_weights[i]\n",
    "            self.biases[i] -= learning_rate * delta_biases[i]\n",
    "\n",
    "    def train(self, inputs, targets, epochs, learning_rate):\n",
    "        targets = one_hot(targets, 10)\n",
    "\n",
    "        errors = []\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            predictions = self.forward(inputs, training=True)\n",
    "            error = cross_entropy_loss(predictions, targets)\n",
    "            self.backward(targets, learning_rate)\n",
    "            errors.append(error)\n",
    "\n",
    "            if epoch % 10 == 0:\n",
    "                print(f'Epoch {epoch}, Error: {error}')\n",
    "\n",
    "        return errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Error: 2.8347622914310113\n",
      "Epoch 10, Error: 2.584034653545719\n",
      "Epoch 20, Error: 2.576708561948397\n",
      "Epoch 30, Error: 2.5634259828688353\n",
      "Epoch 40, Error: 2.5444277988779636\n",
      "Epoch 50, Error: 2.5514630365111057\n",
      "Epoch 60, Error: 2.5442052437184186\n",
      "Epoch 70, Error: 2.5246153301062706\n",
      "Epoch 80, Error: 2.5304585828005255\n",
      "Epoch 90, Error: 2.5142585998873153\n",
      "Epoch 100, Error: 2.5113063027825686\n",
      "Epoch 110, Error: 2.5180615571681253\n",
      "Epoch 120, Error: 2.500633209364342\n",
      "Epoch 130, Error: 2.487416893284751\n",
      "Epoch 140, Error: 2.4892244982677316\n",
      "Epoch 150, Error: 2.4845740738069035\n",
      "Epoch 160, Error: 2.4687288180765274\n",
      "Epoch 170, Error: 2.4663125528498084\n",
      "Epoch 180, Error: 2.4636310912035695\n",
      "Epoch 190, Error: 2.4667570054959995\n",
      "Epoch 200, Error: 2.449703402118532\n",
      "Epoch 210, Error: 2.4465359270670812\n",
      "Epoch 220, Error: 2.4483331509194146\n",
      "Epoch 230, Error: 2.428616256642728\n",
      "Epoch 240, Error: 2.430787115031145\n",
      "Epoch 250, Error: 2.4208043288391305\n",
      "Epoch 260, Error: 2.4179419673853\n",
      "Epoch 270, Error: 2.431508983911089\n",
      "Epoch 280, Error: 2.4111821138673903\n",
      "Epoch 290, Error: 2.399401163523766\n",
      "Test Accuracy: 0.1069423929098966\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_classes = 10\n",
    "input_size = 3072\n",
    "hidden_layers = [256,256,256]  # Tamaños de las capas ocultas\n",
    "output_size = 10\n",
    "layer_sizes = [input_size] + hidden_layers + [output_size]\n",
    "epochs = 300\n",
    "learning_rate = 0.05\n",
    "dropout_rate = 0.5\n",
    "\n",
    "\n",
    "model = MultiLayerNetwork_Dropout(layer_sizes, dropout_rate)\n",
    "errors = model.train(X_train, y_train, epochs, learning_rate)\n",
    "#Evaluar\n",
    "predictions = model.predict(X_train)\n",
    "accuracy = cp.mean(predictions.argmax(axis=1) == y_train)\n",
    "print(f'Test Accuracy: {accuracy}')\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Porcentaje para cada canal RGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_pixels = []\n",
    "green_pixels = []\n",
    "blue_pixels = []\n",
    "train_data = train_data[:, 1:-1]\n",
    "\n",
    "# Iterate through each row in the original matrix\n",
    "for row in train_data:\n",
    "    pr = []\n",
    "    pg = []\n",
    "    pb = []\n",
    "    for i in range(len(row)):\n",
    "        if i % 3 == 0:\n",
    "            pr.append(row[i])\n",
    "        \n",
    "        if i % 3 == 1:\n",
    "            pg.append(row[i])\n",
    "\n",
    "        if i % 3 == 2:\n",
    "            pb.append(row[i])\n",
    "\n",
    "    red_pixels.append(pr)\n",
    "    green_pixels.append(pg)\n",
    "    blue_pixels.append(pb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Más datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10155, 12)\n"
     ]
    }
   ],
   "source": [
    "#intensidad media por conal\n",
    "mean_red = np.mean(red_pixels, axis=1)\n",
    "mean_green = np.mean(green_pixels, axis=1)\n",
    "mean_blue = np.mean(blue_pixels, axis=1)\n",
    "\n",
    "#varianza\n",
    "var_red = np.var(red_pixels, axis=1)\n",
    "var_green = np.var(green_pixels, axis=1)\n",
    "var_blue = np.var(blue_pixels, axis=1)\n",
    "\n",
    "#desviación estándar\n",
    "std_red = np.std(red_pixels, axis=1)\n",
    "std_green = np.std(green_pixels, axis=1)\n",
    "std_blue = np.std(blue_pixels, axis=1)\n",
    "\n",
    "#contraste\n",
    "contrast_red = np.ptp(red_pixels, axis=1) # ptp: peak to peak (max - min)\n",
    "contrast_green = np.ptp(green_pixels, axis=1)\n",
    "contrast_blue = np.ptp(blue_pixels, axis=1)\n",
    "\n",
    "channel_data = np.column_stack((\n",
    "                                mean_red, mean_green, mean_blue,\n",
    "                                var_red, var_green, var_blue,\n",
    "                                std_red, std_green, std_blue,\n",
    "                                contrast_red, contrast_green, contrast_blue\n",
    "                                ))\n",
    "\n",
    "print(channel_data.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train modelo con dataset de parámetros por imagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10155, 12)\n",
      "(10155, 12)\n",
      "(10155, 1)\n",
      "Epoch 0, Error: 2.3898330489527955\n",
      "Epoch 1, Error: 2.305420540347304\n",
      "Epoch 2, Error: 2.2993254481969383\n",
      "Epoch 3, Error: 2.2980342028294842\n",
      "Epoch 4, Error: 2.296853625997203\n",
      "Epoch 5, Error: 2.295580123332472\n",
      "Epoch 6, Error: 2.294407309628787\n",
      "Epoch 7, Error: 2.2933180946727147\n",
      "Epoch 8, Error: 2.2921351846705575\n",
      "Epoch 9, Error: 2.2909355283446677\n",
      "Epoch 10, Error: 2.2898134129250827\n",
      "Epoch 11, Error: 2.2887518566303573\n",
      "Epoch 12, Error: 2.287658902915746\n",
      "Epoch 13, Error: 2.2867520190151156\n",
      "Epoch 14, Error: 2.285809374551954\n",
      "Epoch 15, Error: 2.284745352687388\n",
      "Epoch 16, Error: 2.2839174179325687\n",
      "Epoch 17, Error: 2.2829906714130854\n",
      "Epoch 18, Error: 2.282192554418014\n",
      "Epoch 19, Error: 2.2814327463800157\n",
      "Epoch 20, Error: 2.28057490864808\n",
      "Epoch 21, Error: 2.279695240690646\n",
      "Epoch 22, Error: 2.2790111759546567\n",
      "Epoch 23, Error: 2.2780190170273493\n",
      "Epoch 24, Error: 2.277354033945844\n",
      "Epoch 25, Error: 2.27640258123909\n",
      "Epoch 26, Error: 2.275621141128945\n",
      "Epoch 27, Error: 2.2747430916905826\n",
      "Epoch 28, Error: 2.274080365541309\n",
      "Epoch 29, Error: 2.2731963519552223\n",
      "Epoch 30, Error: 2.2724366423485134\n",
      "Epoch 31, Error: 2.271638020903457\n",
      "Epoch 32, Error: 2.2708489088614607\n",
      "Epoch 33, Error: 2.26988200024238\n",
      "Epoch 34, Error: 2.268951131395263\n",
      "Epoch 35, Error: 2.268268315732128\n",
      "Epoch 36, Error: 2.267467649825344\n",
      "Epoch 37, Error: 2.266552916658833\n",
      "Epoch 38, Error: 2.265886447481918\n",
      "Epoch 39, Error: 2.2650596379072074\n",
      "Epoch 40, Error: 2.264303925315086\n",
      "Epoch 41, Error: 2.2636419252583293\n",
      "Epoch 42, Error: 2.2629896514654413\n",
      "Epoch 43, Error: 2.2621921493495027\n",
      "Epoch 44, Error: 2.2613606623189426\n",
      "Epoch 45, Error: 2.260616541881549\n",
      "Epoch 46, Error: 2.259829022660192\n",
      "Epoch 47, Error: 2.2589423292504573\n",
      "Epoch 48, Error: 2.2582416540721533\n",
      "Epoch 49, Error: 2.2574584680804795\n",
      "Epoch 50, Error: 2.2567066465815673\n",
      "Epoch 51, Error: 2.2560474417748533\n",
      "Epoch 52, Error: 2.2554467516420815\n",
      "Epoch 53, Error: 2.254690537308975\n",
      "Epoch 54, Error: 2.253893623297666\n",
      "Epoch 55, Error: 2.253176115745448\n",
      "Epoch 56, Error: 2.2525468566203872\n",
      "Epoch 57, Error: 2.251955130934161\n",
      "Epoch 58, Error: 2.2512230744717585\n",
      "Epoch 59, Error: 2.2505321993143785\n",
      "Epoch 60, Error: 2.249874041192912\n",
      "Epoch 61, Error: 2.249091490070093\n",
      "Epoch 62, Error: 2.2484270642682413\n",
      "Epoch 63, Error: 2.247820547393881\n",
      "Epoch 64, Error: 2.24719345565533\n",
      "Epoch 65, Error: 2.246503645216834\n",
      "Epoch 66, Error: 2.24581422391216\n",
      "Epoch 67, Error: 2.2450996836529975\n",
      "Epoch 68, Error: 2.24465330606162\n",
      "Epoch 69, Error: 2.2438613203275892\n",
      "Epoch 70, Error: 2.2431410603958137\n",
      "Epoch 71, Error: 2.242520376714124\n",
      "Epoch 72, Error: 2.2419985344922857\n",
      "Epoch 73, Error: 2.2411786378943797\n",
      "Epoch 74, Error: 2.240486142352996\n",
      "Epoch 75, Error: 2.239922048885123\n",
      "Epoch 76, Error: 2.239255883788035\n",
      "Epoch 77, Error: 2.238700314635491\n",
      "Epoch 78, Error: 2.238142622950834\n",
      "Epoch 79, Error: 2.2375077192225414\n",
      "Epoch 80, Error: 2.2368239157877\n",
      "Epoch 81, Error: 2.2362708763128882\n",
      "Epoch 82, Error: 2.235394265676515\n",
      "Epoch 83, Error: 2.2348050971832207\n",
      "Epoch 84, Error: 2.2340086600228495\n",
      "Epoch 85, Error: 2.233370080572933\n",
      "Epoch 86, Error: 2.2326244153450245\n",
      "Epoch 87, Error: 2.2322273108421484\n",
      "Epoch 88, Error: 2.231565843089407\n",
      "Epoch 89, Error: 2.2307565988531843\n",
      "Epoch 90, Error: 2.2301631510890454\n",
      "Epoch 91, Error: 2.2293748933782824\n",
      "Epoch 92, Error: 2.2287511693579463\n",
      "Epoch 93, Error: 2.2279625113175787\n",
      "Epoch 94, Error: 2.22726560701392\n",
      "Epoch 95, Error: 2.226920982246581\n",
      "Epoch 96, Error: 2.2262741600279847\n",
      "Epoch 97, Error: 2.2256207998185715\n",
      "Epoch 98, Error: 2.2249429652241655\n",
      "Epoch 99, Error: 2.2244601960899697\n",
      "Epoch 100, Error: 2.223708909247206\n",
      "Epoch 101, Error: 2.2233443822571717\n",
      "Epoch 102, Error: 2.222761934499413\n",
      "Epoch 103, Error: 2.222215752785838\n",
      "Epoch 104, Error: 2.221456228923419\n",
      "Epoch 105, Error: 2.2208655756769784\n",
      "Epoch 106, Error: 2.220235209642244\n",
      "Epoch 107, Error: 2.219638415024321\n",
      "Epoch 108, Error: 2.218801980596879\n",
      "Epoch 109, Error: 2.2183697153045436\n",
      "Epoch 110, Error: 2.2179542178150857\n",
      "Epoch 111, Error: 2.217367769759126\n",
      "Epoch 112, Error: 2.2168171570754738\n",
      "Epoch 113, Error: 2.2158875874856587\n",
      "Epoch 114, Error: 2.2152761138285846\n",
      "Epoch 115, Error: 2.2146674194240457\n",
      "Epoch 116, Error: 2.21407666233425\n",
      "Epoch 117, Error: 2.21356667654833\n",
      "Epoch 118, Error: 2.212966469288335\n",
      "Epoch 119, Error: 2.2123403246486477\n",
      "Epoch 120, Error: 2.2119438739195223\n",
      "Epoch 121, Error: 2.211085482906895\n",
      "Epoch 122, Error: 2.2105040985698876\n",
      "Epoch 123, Error: 2.2102930276494117\n",
      "Epoch 124, Error: 2.2094524455012765\n",
      "Epoch 125, Error: 2.2092777020723853\n",
      "Epoch 126, Error: 2.2084925659210826\n",
      "Epoch 127, Error: 2.208125226694121\n",
      "Epoch 128, Error: 2.2074939304947527\n",
      "Epoch 129, Error: 2.206367394054554\n",
      "Epoch 130, Error: 2.2060784773956827\n",
      "Epoch 131, Error: 2.2054128241892155\n",
      "Epoch 132, Error: 2.2049823685807795\n",
      "Epoch 133, Error: 2.2040857915476395\n",
      "Epoch 134, Error: 2.203862408070493\n",
      "Epoch 135, Error: 2.2032473033295656\n",
      "Epoch 136, Error: 2.2026441032408197\n",
      "Epoch 137, Error: 2.2018483239140023\n",
      "Epoch 138, Error: 2.2013998996592483\n",
      "Epoch 139, Error: 2.200670766131685\n",
      "Epoch 140, Error: 2.1999352617646304\n",
      "Epoch 141, Error: 2.199280955333771\n",
      "Epoch 142, Error: 2.1988200944249003\n",
      "Epoch 143, Error: 2.1985077595530114\n",
      "Epoch 144, Error: 2.1977773199504766\n",
      "Epoch 145, Error: 2.1977467413410134\n",
      "Epoch 146, Error: 2.1971836569381757\n",
      "Epoch 147, Error: 2.196276580681382\n",
      "Epoch 148, Error: 2.195720309120088\n",
      "Epoch 149, Error: 2.1954285871768806\n",
      "Epoch 150, Error: 2.1953191284471254\n",
      "Epoch 151, Error: 2.1949892274968796\n",
      "Epoch 152, Error: 2.1938792482125735\n",
      "Epoch 153, Error: 2.1942487283776293\n",
      "Epoch 154, Error: 2.193118916337615\n",
      "Epoch 155, Error: 2.192533062313456\n",
      "Epoch 156, Error: 2.192931182341289\n",
      "Epoch 157, Error: 2.1922728826001077\n",
      "Epoch 158, Error: 2.1906501804618332\n",
      "Epoch 159, Error: 2.189844112394967\n",
      "Epoch 160, Error: 2.190561429563632\n",
      "Epoch 161, Error: 2.19026662156548\n",
      "Epoch 162, Error: 2.1887701247678084\n",
      "Epoch 163, Error: 2.1879425363699005\n",
      "Epoch 164, Error: 2.187936801641232\n",
      "Epoch 165, Error: 2.1869018801498212\n",
      "Epoch 166, Error: 2.1868203511438162\n",
      "Epoch 167, Error: 2.1867375173685715\n",
      "Epoch 168, Error: 2.1887437653972137\n",
      "Epoch 169, Error: 2.1871275498891225\n",
      "Epoch 170, Error: 2.185371837882004\n",
      "Epoch 171, Error: 2.1843224304380304\n",
      "Epoch 172, Error: 2.1840493451702154\n",
      "Epoch 173, Error: 2.1831361417731223\n",
      "Epoch 174, Error: 2.182979658405865\n",
      "Epoch 175, Error: 2.183566740287627\n",
      "Epoch 176, Error: 2.18204083729702\n",
      "Epoch 177, Error: 2.1814231505333064\n",
      "Epoch 178, Error: 2.180600185900279\n",
      "Epoch 179, Error: 2.1804383215281464\n",
      "Epoch 180, Error: 2.1800637664318097\n",
      "Epoch 181, Error: 2.180178045879265\n",
      "Epoch 182, Error: 2.184297622446921\n",
      "Epoch 183, Error: 2.182400604754268\n",
      "Epoch 184, Error: 2.1811264589675927\n",
      "Epoch 185, Error: 2.180193975418561\n",
      "Epoch 186, Error: 2.1790226867040925\n",
      "Epoch 187, Error: 2.177880544337304\n",
      "Epoch 188, Error: 2.178631338440389\n",
      "Epoch 189, Error: 2.180002988740951\n",
      "Epoch 190, Error: 2.1781502735801537\n",
      "Epoch 191, Error: 2.177855110542243\n",
      "Epoch 192, Error: 2.1752674215344063\n",
      "Epoch 193, Error: 2.1744531379384995\n",
      "Epoch 194, Error: 2.174907766573883\n",
      "Epoch 195, Error: 2.1755523094741873\n",
      "Epoch 196, Error: 2.1765972804786937\n",
      "Epoch 197, Error: 2.176757776730949\n",
      "Epoch 198, Error: 2.174981065051112\n",
      "Epoch 199, Error: 2.1734991357422335\n",
      "Epoch 200, Error: 2.171690205543437\n",
      "Epoch 201, Error: 2.172095328753055\n",
      "Epoch 202, Error: 2.173530161641429\n",
      "Epoch 203, Error: 2.172579612322535\n",
      "Epoch 204, Error: 2.1702828271898147\n",
      "Epoch 205, Error: 2.1698700678588922\n",
      "Epoch 206, Error: 2.172446946013857\n",
      "Epoch 207, Error: 2.175084445579073\n",
      "Epoch 208, Error: 2.172349168412642\n",
      "Epoch 209, Error: 2.1707058705314375\n",
      "Epoch 210, Error: 2.1698772595263325\n",
      "Epoch 211, Error: 2.16971727450707\n",
      "Epoch 212, Error: 2.168909708526937\n",
      "Epoch 213, Error: 2.1710826680875512\n",
      "Epoch 214, Error: 2.1724165026932556\n",
      "Epoch 215, Error: 2.171019121764777\n",
      "Epoch 216, Error: 2.1692108201287854\n",
      "Epoch 217, Error: 2.1673684693236224\n",
      "Epoch 218, Error: 2.166707885820514\n",
      "Epoch 219, Error: 2.1641434511538664\n",
      "Epoch 220, Error: 2.1653846677590525\n",
      "Epoch 221, Error: 2.168394569542757\n",
      "Epoch 222, Error: 2.166611890606963\n",
      "Epoch 223, Error: 2.1651296854739717\n",
      "Epoch 224, Error: 2.1654058534358978\n",
      "Epoch 225, Error: 2.163607132093339\n",
      "Epoch 226, Error: 2.162348700783427\n",
      "Epoch 227, Error: 2.1620304383414943\n",
      "Epoch 228, Error: 2.16112184686731\n",
      "Epoch 229, Error: 2.161466159188828\n",
      "Epoch 230, Error: 2.1634713232885425\n",
      "Epoch 231, Error: 2.165250914284337\n",
      "Epoch 232, Error: 2.163536291050366\n",
      "Epoch 233, Error: 2.161943294872026\n",
      "Epoch 234, Error: 2.16231690150816\n",
      "Epoch 235, Error: 2.1589154358229585\n",
      "Epoch 236, Error: 2.158561939746547\n",
      "Epoch 237, Error: 2.1580123075532396\n",
      "Epoch 238, Error: 2.1574389179971685\n",
      "Epoch 239, Error: 2.1582473103531026\n",
      "Epoch 240, Error: 2.1569906869751523\n",
      "Epoch 241, Error: 2.1585168574815397\n",
      "Epoch 242, Error: 2.15683711243989\n",
      "Epoch 243, Error: 2.1559350527454217\n",
      "Epoch 244, Error: 2.161892527251204\n",
      "Epoch 245, Error: 2.162821672026017\n",
      "Epoch 246, Error: 2.1582331573966598\n",
      "Epoch 247, Error: 2.1588283407260653\n",
      "Epoch 248, Error: 2.1563855009275756\n",
      "Epoch 249, Error: 2.1549971804831\n",
      "Epoch 250, Error: 2.155023557374584\n",
      "Epoch 251, Error: 2.1619840934625985\n",
      "Epoch 252, Error: 2.16676696257194\n",
      "Epoch 253, Error: 2.1625803062848874\n",
      "Epoch 254, Error: 2.1622596536022756\n",
      "Epoch 255, Error: 2.161737187280243\n",
      "Epoch 256, Error: 2.1594791753548774\n",
      "Epoch 257, Error: 2.158744320037394\n",
      "Epoch 258, Error: 2.157584766800005\n",
      "Epoch 259, Error: 2.1563942107670906\n",
      "Epoch 260, Error: 2.1544616199298217\n",
      "Epoch 261, Error: 2.1532000140816048\n",
      "Epoch 262, Error: 2.151790188829985\n",
      "Epoch 263, Error: 2.1529047184764205\n",
      "Epoch 264, Error: 2.151121378243258\n",
      "Epoch 265, Error: 2.156015641401349\n",
      "Epoch 266, Error: 2.149962822461051\n",
      "Epoch 267, Error: 2.1499625290484707\n",
      "Epoch 268, Error: 2.152550658453137\n",
      "Epoch 269, Error: 2.1562653636444478\n",
      "Epoch 270, Error: 2.1552761569740864\n",
      "Epoch 271, Error: 2.1561240219983877\n",
      "Epoch 272, Error: 2.1529391160770786\n",
      "Epoch 273, Error: 2.151920872833035\n",
      "Epoch 274, Error: 2.1495046331427483\n",
      "Epoch 275, Error: 2.1482901310042175\n",
      "Epoch 276, Error: 2.1484079747620712\n",
      "Epoch 277, Error: 2.1515241004239276\n",
      "Epoch 278, Error: 2.147516600646812\n",
      "Epoch 279, Error: 2.1461415569650826\n",
      "Epoch 280, Error: 2.147396217685383\n",
      "Epoch 281, Error: 2.1486600608471216\n",
      "Epoch 282, Error: 2.1485166519415957\n",
      "Epoch 283, Error: 2.1467883476312233\n",
      "Epoch 284, Error: 2.145723966725992\n",
      "Epoch 285, Error: 2.145842736011879\n",
      "Epoch 286, Error: 2.144633116394137\n",
      "Epoch 287, Error: 2.1494590259274373\n",
      "Epoch 288, Error: 2.14877926047066\n",
      "Epoch 289, Error: 2.148178163489391\n",
      "Epoch 290, Error: 2.148998513408431\n",
      "Epoch 291, Error: 2.149262993208468\n",
      "Epoch 292, Error: 2.149946383584412\n",
      "Epoch 293, Error: 2.1508743170812705\n",
      "Epoch 294, Error: 2.1488402856726054\n",
      "Epoch 295, Error: 2.1547456322381318\n",
      "Epoch 296, Error: 2.1475458858536722\n",
      "Epoch 297, Error: 2.145285549800251\n",
      "Epoch 298, Error: 2.1456077272512672\n",
      "Epoch 299, Error: 2.148685315526083\n",
      "Epoch 300, Error: 2.147500462663101\n",
      "Epoch 301, Error: 2.146144404959051\n",
      "Epoch 302, Error: 2.1444010235161968\n",
      "Epoch 303, Error: 2.14270282333912\n",
      "Epoch 304, Error: 2.1419995017494307\n",
      "Epoch 305, Error: 2.1460534723839926\n",
      "Epoch 306, Error: 2.1445475261244034\n",
      "Epoch 307, Error: 2.150000071290377\n",
      "Epoch 308, Error: 2.1480602610786392\n",
      "Epoch 309, Error: 2.1511477645530475\n",
      "Epoch 310, Error: 2.14790278887358\n",
      "Epoch 311, Error: 2.146862647437594\n",
      "Epoch 312, Error: 2.14651327143292\n",
      "Epoch 313, Error: 2.145649820468555\n",
      "Epoch 314, Error: 2.144154995925368\n",
      "Epoch 315, Error: 2.143797336353342\n",
      "Epoch 316, Error: 2.146171429104812\n",
      "Epoch 317, Error: 2.1486011245842462\n",
      "Epoch 318, Error: 2.142746289481959\n",
      "Epoch 319, Error: 2.1407058828949435\n",
      "Epoch 320, Error: 2.1382671552134873\n",
      "Epoch 321, Error: 2.138520325116373\n",
      "Epoch 322, Error: 2.136796902700004\n",
      "Epoch 323, Error: 2.1369589403678795\n",
      "Epoch 324, Error: 2.139376929610836\n",
      "Epoch 325, Error: 2.13960019395261\n",
      "Epoch 326, Error: 2.14403904206356\n",
      "Epoch 327, Error: 2.141919972775913\n",
      "Epoch 328, Error: 2.1466114443840136\n",
      "Epoch 329, Error: 2.1421178406181\n",
      "Epoch 330, Error: 2.140770705084297\n",
      "Epoch 331, Error: 2.1417568887054763\n",
      "Epoch 332, Error: 2.1408519717919896\n",
      "Epoch 333, Error: 2.141838974897152\n",
      "Epoch 334, Error: 2.144167567536981\n",
      "Epoch 335, Error: 2.146091320638658\n",
      "Epoch 336, Error: 2.1419054701022184\n",
      "Epoch 337, Error: 2.1409699144588354\n",
      "Epoch 338, Error: 2.1400277213369807\n",
      "Epoch 339, Error: 2.141514894326361\n",
      "Epoch 340, Error: 2.139852861295234\n",
      "Epoch 341, Error: 2.139187697104687\n",
      "Epoch 342, Error: 2.1384446594923197\n",
      "Epoch 343, Error: 2.135170544374184\n",
      "Epoch 344, Error: 2.136859578559609\n",
      "Epoch 345, Error: 2.134000524630648\n",
      "Epoch 346, Error: 2.134895785866876\n",
      "Epoch 347, Error: 2.137407688037755\n",
      "Epoch 348, Error: 2.138330864166444\n",
      "Epoch 349, Error: 2.137939783780664\n",
      "Epoch 350, Error: 2.1404301618901242\n",
      "Epoch 351, Error: 2.142120966874421\n",
      "Epoch 352, Error: 2.145723134542723\n",
      "Epoch 353, Error: 2.137207302737648\n",
      "Epoch 354, Error: 2.135168031687452\n",
      "Epoch 355, Error: 2.13516077020134\n",
      "Epoch 356, Error: 2.137392570458126\n",
      "Epoch 357, Error: 2.138415013360106\n",
      "Epoch 358, Error: 2.1376304630271963\n",
      "Epoch 359, Error: 2.1348581507381614\n",
      "Epoch 360, Error: 2.1325678225552562\n",
      "Epoch 361, Error: 2.1348535782384457\n",
      "Epoch 362, Error: 2.134480317315099\n",
      "Epoch 363, Error: 2.133782071937606\n",
      "Epoch 364, Error: 2.1318362966678883\n",
      "Epoch 365, Error: 2.1309972864882494\n",
      "Epoch 366, Error: 2.1324255184808827\n",
      "Epoch 367, Error: 2.1381478111271934\n",
      "Epoch 368, Error: 2.1374509821986147\n",
      "Epoch 369, Error: 2.1332774116335442\n",
      "Epoch 370, Error: 2.1321455322029537\n",
      "Epoch 371, Error: 2.1372478834690796\n",
      "Epoch 372, Error: 2.1487827524889234\n",
      "Epoch 373, Error: 2.1363167913256964\n",
      "Epoch 374, Error: 2.134165876806332\n",
      "Epoch 375, Error: 2.1386633638875825\n",
      "Epoch 376, Error: 2.139450275751815\n",
      "Epoch 377, Error: 2.135945208521205\n",
      "Epoch 378, Error: 2.1321786474598134\n",
      "Epoch 379, Error: 2.1308091162088676\n",
      "Epoch 380, Error: 2.129817920189004\n",
      "Epoch 381, Error: 2.130050516601715\n",
      "Epoch 382, Error: 2.1356614510826795\n",
      "Epoch 383, Error: 2.145073392059616\n",
      "Epoch 384, Error: 2.1349796303828175\n",
      "Epoch 385, Error: 2.1340938158786638\n",
      "Epoch 386, Error: 2.134705058468942\n",
      "Epoch 387, Error: 2.130759431199512\n",
      "Epoch 388, Error: 2.129796511323076\n",
      "Epoch 389, Error: 2.1284025464471776\n",
      "Epoch 390, Error: 2.1295093360405737\n",
      "Epoch 391, Error: 2.1342635386703934\n",
      "Epoch 392, Error: 2.1305347868673663\n",
      "Epoch 393, Error: 2.129621295965931\n",
      "Epoch 394, Error: 2.1291108105230934\n",
      "Epoch 395, Error: 2.135670913934264\n",
      "Epoch 396, Error: 2.131062118621135\n",
      "Epoch 397, Error: 2.1316666475015005\n",
      "Epoch 398, Error: 2.1291981931506214\n",
      "Epoch 399, Error: 2.130907703923368\n",
      "Epoch 400, Error: 2.131373590193549\n",
      "Epoch 401, Error: 2.1336722886592465\n",
      "Epoch 402, Error: 2.1346293765439874\n",
      "Epoch 403, Error: 2.1395941190729735\n",
      "Epoch 404, Error: 2.1296486557771424\n",
      "Epoch 405, Error: 2.127987854140201\n",
      "Epoch 406, Error: 2.1344494682007786\n",
      "Epoch 407, Error: 2.13607275627317\n",
      "Epoch 408, Error: 2.13537794191387\n",
      "Epoch 409, Error: 2.135359626233027\n",
      "Epoch 410, Error: 2.1320058719295485\n",
      "Epoch 411, Error: 2.1321352667155646\n",
      "Epoch 412, Error: 2.1285990663559495\n",
      "Epoch 413, Error: 2.1286477246524225\n",
      "Epoch 414, Error: 2.1267966506989437\n",
      "Epoch 415, Error: 2.125240176880822\n",
      "Epoch 416, Error: 2.1302428091071985\n",
      "Epoch 417, Error: 2.136052613547751\n",
      "Epoch 418, Error: 2.1343840736287683\n",
      "Epoch 419, Error: 2.1403337560581877\n",
      "Epoch 420, Error: 2.1333275137411998\n",
      "Epoch 421, Error: 2.131599699691324\n",
      "Epoch 422, Error: 2.133053892824565\n",
      "Epoch 423, Error: 2.136807537579981\n",
      "Epoch 424, Error: 2.128448961163771\n",
      "Epoch 425, Error: 2.1251027577645085\n",
      "Epoch 426, Error: 2.133450695113165\n",
      "Epoch 427, Error: 2.144923818187096\n",
      "Epoch 428, Error: 2.13774445917435\n",
      "Epoch 429, Error: 2.1465928471541353\n",
      "Epoch 430, Error: 2.1351245605677205\n",
      "Epoch 431, Error: 2.1332720577513835\n",
      "Epoch 432, Error: 2.1292989555040642\n",
      "Epoch 433, Error: 2.1268924352186898\n",
      "Epoch 434, Error: 2.1269900195071174\n",
      "Epoch 435, Error: 2.1243430031844834\n",
      "Epoch 436, Error: 2.135735173046596\n",
      "Epoch 437, Error: 2.1301158680721777\n",
      "Epoch 438, Error: 2.137112591604735\n",
      "Epoch 439, Error: 2.1327216554048056\n",
      "Epoch 440, Error: 2.127000162912534\n",
      "Epoch 441, Error: 2.13285201484158\n",
      "Epoch 442, Error: 2.1290361260494066\n",
      "Epoch 443, Error: 2.128927022434344\n",
      "Epoch 444, Error: 2.132129978149671\n",
      "Epoch 445, Error: 2.1318681920431732\n",
      "Epoch 446, Error: 2.1302070044495887\n",
      "Epoch 447, Error: 2.1314315736068457\n",
      "Epoch 448, Error: 2.127046679037943\n",
      "Epoch 449, Error: 2.1257482932751497\n",
      "Epoch 450, Error: 2.1330505443798664\n",
      "Epoch 451, Error: 2.135817401579584\n",
      "Epoch 452, Error: 2.1356936007718224\n",
      "Epoch 453, Error: 2.1418388542536144\n",
      "Epoch 454, Error: 2.1313704346052664\n",
      "Epoch 455, Error: 2.132160505405768\n",
      "Epoch 456, Error: 2.1264966854875733\n",
      "Epoch 457, Error: 2.1241723517186726\n",
      "Epoch 458, Error: 2.1254902920963006\n",
      "Epoch 459, Error: 2.1235607780762926\n",
      "Epoch 460, Error: 2.12266092387789\n",
      "Epoch 461, Error: 2.125836245523381\n",
      "Epoch 462, Error: 2.128100137436106\n",
      "Epoch 463, Error: 2.1276709445420807\n",
      "Epoch 464, Error: 2.1259072120583093\n",
      "Epoch 465, Error: 2.124725513797422\n",
      "Epoch 466, Error: 2.1242866591939777\n",
      "Epoch 467, Error: 2.1239062534138435\n",
      "Epoch 468, Error: 2.1248442992757965\n",
      "Epoch 469, Error: 2.1230323084094773\n",
      "Epoch 470, Error: 2.121562955213318\n",
      "Epoch 471, Error: 2.1252884710998563\n",
      "Epoch 472, Error: 2.1234026215077377\n",
      "Epoch 473, Error: 2.124586104541186\n",
      "Epoch 474, Error: 2.1282208067769313\n",
      "Epoch 475, Error: 2.126325720949416\n",
      "Epoch 476, Error: 2.1247934636832904\n",
      "Epoch 477, Error: 2.1287560258607328\n",
      "Epoch 478, Error: 2.1331216918461813\n",
      "Epoch 479, Error: 2.1240948029319298\n",
      "Epoch 480, Error: 2.1238600023867744\n",
      "Epoch 481, Error: 2.1208540061418146\n",
      "Epoch 482, Error: 2.123284678694532\n",
      "Epoch 483, Error: 2.123936442285094\n",
      "Epoch 484, Error: 2.1314163704584534\n",
      "Epoch 485, Error: 2.1344368702984395\n",
      "Epoch 486, Error: 2.132678149224462\n",
      "Epoch 487, Error: 2.1356590964354973\n",
      "Epoch 488, Error: 2.1253918897903263\n",
      "Epoch 489, Error: 2.122887032372889\n",
      "Epoch 490, Error: 2.1253605054316167\n",
      "Epoch 491, Error: 2.130148325745464\n",
      "Epoch 492, Error: 2.1261142094910594\n",
      "Epoch 493, Error: 2.1305399945422874\n",
      "Epoch 494, Error: 2.1221622910382805\n",
      "Epoch 495, Error: 2.1278859379314654\n",
      "Epoch 496, Error: 2.1232237459599173\n",
      "Epoch 497, Error: 2.122514451628103\n",
      "Epoch 498, Error: 2.1192124103351873\n",
      "Epoch 499, Error: 2.120123768917123\n",
      "Epoch 500, Error: 2.1236383198412914\n",
      "Epoch 501, Error: 2.1250149193227745\n",
      "Epoch 502, Error: 2.1272733308968808\n",
      "Epoch 503, Error: 2.1383252911461708\n",
      "Epoch 504, Error: 2.1275504749513345\n",
      "Epoch 505, Error: 2.1347580052361943\n",
      "Epoch 506, Error: 2.1406932054800074\n",
      "Epoch 507, Error: 2.15674261944407\n",
      "Epoch 508, Error: 2.1336345866270476\n",
      "Epoch 509, Error: 2.132451072406256\n",
      "Epoch 510, Error: 2.126802935341796\n",
      "Epoch 511, Error: 2.1234266021998205\n",
      "Epoch 512, Error: 2.1244019849769353\n",
      "Epoch 513, Error: 2.123474827763196\n",
      "Epoch 514, Error: 2.1212039385642294\n",
      "Epoch 515, Error: 2.120417359253562\n",
      "Epoch 516, Error: 2.1201007243222714\n",
      "Epoch 517, Error: 2.1185905319775933\n",
      "Epoch 518, Error: 2.1208505277056764\n",
      "Epoch 519, Error: 2.1217820210969687\n",
      "Epoch 520, Error: 2.1201968388630243\n",
      "Epoch 521, Error: 2.1225432618871047\n",
      "Epoch 522, Error: 2.11982440822079\n",
      "Epoch 523, Error: 2.119165856850495\n",
      "Epoch 524, Error: 2.124807490127259\n",
      "Epoch 525, Error: 2.1380899938204245\n",
      "Epoch 526, Error: 2.123533209386925\n",
      "Epoch 527, Error: 2.123390347435003\n",
      "Epoch 528, Error: 2.1200664397516262\n",
      "Epoch 529, Error: 2.118839147951626\n",
      "Epoch 530, Error: 2.1178783492220568\n",
      "Epoch 531, Error: 2.117117229460528\n",
      "Epoch 532, Error: 2.129559093047251\n",
      "Epoch 533, Error: 2.130636096371256\n",
      "Epoch 534, Error: 2.124188864813734\n",
      "Epoch 535, Error: 2.1273470767606217\n",
      "Epoch 536, Error: 2.12883097128685\n",
      "Epoch 537, Error: 2.1333532719152313\n",
      "Epoch 538, Error: 2.1241953110269023\n",
      "Epoch 539, Error: 2.120196608995178\n",
      "Epoch 540, Error: 2.1180588288132136\n",
      "Epoch 541, Error: 2.120302263148176\n",
      "Epoch 542, Error: 2.117327285961334\n",
      "Epoch 543, Error: 2.118936315427688\n",
      "Epoch 544, Error: 2.117631749231\n",
      "Epoch 545, Error: 2.1207291904699765\n",
      "Epoch 546, Error: 2.1177757144717493\n",
      "Epoch 547, Error: 2.120487429542294\n",
      "Epoch 548, Error: 2.1184423164834487\n",
      "Epoch 549, Error: 2.1189999499467556\n",
      "Epoch 550, Error: 2.118121412662424\n",
      "Epoch 551, Error: 2.1207243330524514\n",
      "Epoch 552, Error: 2.1186429006390295\n",
      "Epoch 553, Error: 2.118659422224336\n",
      "Epoch 554, Error: 2.12730473116759\n",
      "Epoch 555, Error: 2.123664208677049\n",
      "Epoch 556, Error: 2.1217053203500575\n",
      "Epoch 557, Error: 2.1219871817510807\n",
      "Epoch 558, Error: 2.12201395486589\n",
      "Epoch 559, Error: 2.122480488316629\n",
      "Epoch 560, Error: 2.122281744709096\n",
      "Epoch 561, Error: 2.1234040608922458\n",
      "Epoch 562, Error: 2.1226541500648857\n",
      "Epoch 563, Error: 2.120685896810265\n",
      "Epoch 564, Error: 2.1237785301436483\n",
      "Epoch 565, Error: 2.1215097605165267\n",
      "Epoch 566, Error: 2.123121743652969\n",
      "Epoch 567, Error: 2.126655358346392\n",
      "Epoch 568, Error: 2.134033240169871\n",
      "Epoch 569, Error: 2.125833780747788\n",
      "Epoch 570, Error: 2.1254414222315567\n",
      "Epoch 571, Error: 2.1214689591280265\n",
      "Epoch 572, Error: 2.121979407623252\n",
      "Epoch 573, Error: 2.122707369155827\n",
      "Epoch 574, Error: 2.1248836490131304\n",
      "Epoch 575, Error: 2.12156791579739\n",
      "Epoch 576, Error: 2.121850957628887\n",
      "Epoch 577, Error: 2.1207080383328845\n",
      "Epoch 578, Error: 2.123339837398769\n",
      "Epoch 579, Error: 2.121518963216709\n",
      "Epoch 580, Error: 2.1241339863191366\n",
      "Epoch 581, Error: 2.1216008368063486\n",
      "Epoch 582, Error: 2.1215392280962244\n",
      "Epoch 583, Error: 2.1199995659388104\n",
      "Epoch 584, Error: 2.12068096851313\n",
      "Epoch 585, Error: 2.1272473245870174\n",
      "Epoch 586, Error: 2.122837095665596\n",
      "Epoch 587, Error: 2.121635398748978\n",
      "Epoch 588, Error: 2.1273855874554126\n",
      "Epoch 589, Error: 2.126636166810519\n",
      "Epoch 590, Error: 2.120231071447853\n",
      "Epoch 591, Error: 2.120839406170311\n",
      "Epoch 592, Error: 2.126003096774094\n",
      "Epoch 593, Error: 2.122830654506922\n",
      "Epoch 594, Error: 2.121600331041031\n",
      "Epoch 595, Error: 2.1214190082813693\n",
      "Epoch 596, Error: 2.1221536953607707\n",
      "Epoch 597, Error: 2.1256506335321466\n",
      "Epoch 598, Error: 2.1216182581457628\n",
      "Epoch 599, Error: 2.1209113951835707\n",
      "Epoch 600, Error: 2.1212391471965804\n",
      "Epoch 601, Error: 2.122937060482383\n",
      "Epoch 602, Error: 2.1254885886216206\n",
      "Epoch 603, Error: 2.121787531419002\n",
      "Epoch 604, Error: 2.1230910963816827\n",
      "Epoch 605, Error: 2.1244429029351135\n",
      "Epoch 606, Error: 2.12155310286795\n",
      "Epoch 607, Error: 2.1204816020920303\n",
      "Epoch 608, Error: 2.1278114964893295\n",
      "Epoch 609, Error: 2.1240343594054005\n",
      "Epoch 610, Error: 2.122662228948373\n",
      "Epoch 611, Error: 2.125146585400595\n",
      "Epoch 612, Error: 2.124751981235835\n",
      "Epoch 613, Error: 2.127515735349444\n",
      "Epoch 614, Error: 2.1235555220537603\n",
      "Epoch 615, Error: 2.1276336331637205\n",
      "Epoch 616, Error: 2.1295890372274355\n",
      "Epoch 617, Error: 2.1238351777914906\n",
      "Epoch 618, Error: 2.1245456699648666\n",
      "Epoch 619, Error: 2.124368736069263\n",
      "Epoch 620, Error: 2.129932497645055\n",
      "Epoch 621, Error: 2.126264655064148\n",
      "Epoch 622, Error: 2.1247041854101147\n",
      "Epoch 623, Error: 2.122128055952243\n",
      "Epoch 624, Error: 2.1215588896235573\n",
      "Epoch 625, Error: 2.122444264337984\n",
      "Epoch 626, Error: 2.1201390626742276\n",
      "Epoch 627, Error: 2.121041342413299\n",
      "Epoch 628, Error: 2.125468017441225\n",
      "Epoch 629, Error: 2.125356231614507\n",
      "Epoch 630, Error: 2.1272901419320407\n",
      "Epoch 631, Error: 2.1349889024765023\n",
      "Epoch 632, Error: 2.126613698848211\n",
      "Epoch 633, Error: 2.1284073816314986\n",
      "Epoch 634, Error: 2.12790941921705\n",
      "Epoch 635, Error: 2.1346813725426608\n",
      "Epoch 636, Error: 2.1254091783143134\n",
      "Epoch 637, Error: 2.1300819128382367\n",
      "Epoch 638, Error: 2.1231439496770594\n",
      "Epoch 639, Error: 2.122211617117067\n",
      "Epoch 640, Error: 2.1212686687094036\n",
      "Epoch 641, Error: 2.1204625692515426\n",
      "Epoch 642, Error: 2.1195925753789484\n",
      "Epoch 643, Error: 2.124409993319375\n",
      "Epoch 644, Error: 2.1195809858360626\n",
      "Epoch 645, Error: 2.123019577535452\n",
      "Epoch 646, Error: 2.119504438725339\n",
      "Epoch 647, Error: 2.124762260408974\n",
      "Epoch 648, Error: 2.127919781237477\n",
      "Epoch 649, Error: 2.1234561475131715\n",
      "Epoch 650, Error: 2.1247537686833007\n",
      "Epoch 651, Error: 2.1215808696502467\n",
      "Epoch 652, Error: 2.1200542674435376\n",
      "Epoch 653, Error: 2.1237804206046276\n",
      "Epoch 654, Error: 2.127015236918633\n",
      "Epoch 655, Error: 2.1254398038564193\n",
      "Epoch 656, Error: 2.123233714719368\n",
      "Epoch 657, Error: 2.1217016598382172\n",
      "Epoch 658, Error: 2.1220433411640807\n",
      "Epoch 659, Error: 2.1322577587221425\n",
      "Epoch 660, Error: 2.129749321441639\n",
      "Epoch 661, Error: 2.132688895457393\n",
      "Epoch 662, Error: 2.124327082773383\n",
      "Epoch 663, Error: 2.122872454884786\n",
      "Epoch 664, Error: 2.121548030844388\n",
      "Epoch 665, Error: 2.1225848580389566\n",
      "Epoch 666, Error: 2.1199025454077565\n",
      "Epoch 667, Error: 2.119213971521747\n",
      "Epoch 668, Error: 2.1222201650056474\n",
      "Epoch 669, Error: 2.1229003493190937\n",
      "Epoch 670, Error: 2.127268089750008\n",
      "Epoch 671, Error: 2.1329537990180043\n",
      "Epoch 672, Error: 2.1232745210343715\n",
      "Epoch 673, Error: 2.1247913646520034\n",
      "Epoch 674, Error: 2.1212870108249247\n",
      "Epoch 675, Error: 2.1201891567121107\n",
      "Epoch 676, Error: 2.1261695135984717\n",
      "Epoch 677, Error: 2.1346279641152197\n",
      "Epoch 678, Error: 2.124371806674988\n",
      "Epoch 679, Error: 2.1208906746522747\n",
      "Epoch 680, Error: 2.1194339162260145\n",
      "Epoch 681, Error: 2.121350279307185\n",
      "Epoch 682, Error: 2.1209948008569337\n",
      "Epoch 683, Error: 2.1208644740179188\n",
      "Epoch 684, Error: 2.1188650921174443\n",
      "Epoch 685, Error: 2.1229616614574778\n",
      "Epoch 686, Error: 2.1223876030526636\n",
      "Epoch 687, Error: 2.127572555742842\n",
      "Epoch 688, Error: 2.1213965492806883\n",
      "Epoch 689, Error: 2.1208747231468505\n",
      "Epoch 690, Error: 2.1206823155925716\n",
      "Epoch 691, Error: 2.1217431097700956\n",
      "Epoch 692, Error: 2.1244644460997204\n",
      "Epoch 693, Error: 2.131902228410493\n",
      "Epoch 694, Error: 2.1212867616343187\n",
      "Epoch 695, Error: 2.1197649590629375\n",
      "Epoch 696, Error: 2.1193136325707744\n",
      "Epoch 697, Error: 2.120869840800456\n",
      "Epoch 698, Error: 2.119349017389636\n",
      "Epoch 699, Error: 2.1193880352562466\n",
      "Epoch 700, Error: 2.119429746701033\n",
      "Epoch 701, Error: 2.117212328270323\n",
      "Epoch 702, Error: 2.1189696725051297\n",
      "Epoch 703, Error: 2.1240902373594244\n",
      "Epoch 704, Error: 2.121399357869716\n",
      "Epoch 705, Error: 2.1292445620528353\n",
      "Epoch 706, Error: 2.128150722849047\n",
      "Epoch 707, Error: 2.1304540698802708\n",
      "Epoch 708, Error: 2.1212407029871927\n",
      "Epoch 709, Error: 2.1211589616120774\n",
      "Epoch 710, Error: 2.125422618038601\n",
      "Epoch 711, Error: 2.1419348284995667\n",
      "Epoch 712, Error: 2.1238688256135325\n",
      "Epoch 713, Error: 2.1188256456393795\n",
      "Epoch 714, Error: 2.1182778372336424\n",
      "Epoch 715, Error: 2.118689927247106\n",
      "Epoch 716, Error: 2.121135087570706\n",
      "Epoch 717, Error: 2.119936031893982\n",
      "Epoch 718, Error: 2.1174463948433884\n",
      "Epoch 719, Error: 2.1191572641607137\n",
      "Epoch 720, Error: 2.1184888904932895\n",
      "Epoch 721, Error: 2.123708064094601\n",
      "Epoch 722, Error: 2.1229013749724612\n",
      "Epoch 723, Error: 2.1217432674195873\n",
      "Epoch 724, Error: 2.1225410192052534\n",
      "Epoch 725, Error: 2.118335311077893\n",
      "Epoch 726, Error: 2.119886273878076\n",
      "Epoch 727, Error: 2.115813774009446\n",
      "Epoch 728, Error: 2.116043539903762\n",
      "Epoch 729, Error: 2.118604996781841\n",
      "Epoch 730, Error: 2.118469732495844\n",
      "Epoch 731, Error: 2.1196286019185266\n",
      "Epoch 732, Error: 2.120611350149376\n",
      "Epoch 733, Error: 2.129379062573373\n",
      "Epoch 734, Error: 2.1361036613595608\n",
      "Epoch 735, Error: 2.131904540335895\n",
      "Epoch 736, Error: 2.133417458766072\n",
      "Epoch 737, Error: 2.121469597459619\n",
      "Epoch 738, Error: 2.120710330335323\n",
      "Epoch 739, Error: 2.117782144215724\n",
      "Epoch 740, Error: 2.1172498272332247\n",
      "Epoch 741, Error: 2.11835514486231\n",
      "Epoch 742, Error: 2.1158804077804865\n",
      "Epoch 743, Error: 2.1165807431507546\n",
      "Epoch 744, Error: 2.11747216144438\n",
      "Epoch 745, Error: 2.1199335735943734\n",
      "Epoch 746, Error: 2.115943117671586\n",
      "Epoch 747, Error: 2.1166064148939423\n",
      "Epoch 748, Error: 2.1154694773358464\n",
      "Epoch 749, Error: 2.1186124714021943\n",
      "Epoch 750, Error: 2.1222954317819043\n",
      "Epoch 751, Error: 2.1191448473348804\n",
      "Epoch 752, Error: 2.126099189487278\n",
      "Epoch 753, Error: 2.119101045136398\n",
      "Epoch 754, Error: 2.117180783651007\n",
      "Epoch 755, Error: 2.1148615268333195\n",
      "Epoch 756, Error: 2.114697376788073\n",
      "Epoch 757, Error: 2.116457610274712\n",
      "Epoch 758, Error: 2.128993364713116\n",
      "Epoch 759, Error: 2.130679017180288\n",
      "Epoch 760, Error: 2.1331763797983894\n",
      "Epoch 761, Error: 2.1304046436318087\n",
      "Epoch 762, Error: 2.1219536745001912\n",
      "Epoch 763, Error: 2.116905505388489\n",
      "Epoch 764, Error: 2.1225698140966482\n",
      "Epoch 765, Error: 2.132858118877749\n",
      "Epoch 766, Error: 2.1234414064232645\n",
      "Epoch 767, Error: 2.1191940680291568\n",
      "Epoch 768, Error: 2.1157538186515783\n",
      "Epoch 769, Error: 2.1146830266864964\n",
      "Epoch 770, Error: 2.1165687382180556\n",
      "Epoch 771, Error: 2.1171116324058423\n",
      "Epoch 772, Error: 2.117375430666703\n",
      "Epoch 773, Error: 2.115964942369003\n",
      "Epoch 774, Error: 2.1169186342947177\n",
      "Epoch 775, Error: 2.115478295509712\n",
      "Epoch 776, Error: 2.1154418414897775\n",
      "Epoch 777, Error: 2.1198535964367022\n",
      "Epoch 778, Error: 2.117908959234133\n",
      "Epoch 779, Error: 2.1175126163634874\n",
      "Epoch 780, Error: 2.117345742802683\n",
      "Epoch 781, Error: 2.119727662270443\n",
      "Epoch 782, Error: 2.1194088413750682\n",
      "Epoch 783, Error: 2.1286449020121485\n",
      "Epoch 784, Error: 2.127702001117496\n",
      "Epoch 785, Error: 2.1173829032955336\n",
      "Epoch 786, Error: 2.118093190387367\n",
      "Epoch 787, Error: 2.1240083839373525\n",
      "Epoch 788, Error: 2.1202043281003697\n",
      "Epoch 789, Error: 2.1304304163754755\n",
      "Epoch 790, Error: 2.115511486338106\n",
      "Epoch 791, Error: 2.115931903715894\n",
      "Epoch 792, Error: 2.1127520005287677\n",
      "Epoch 793, Error: 2.1153575795941584\n",
      "Epoch 794, Error: 2.1115367473890716\n",
      "Epoch 795, Error: 2.1160538140759617\n",
      "Epoch 796, Error: 2.12027938304717\n",
      "Epoch 797, Error: 2.129283028979293\n",
      "Epoch 798, Error: 2.1182804496261096\n",
      "Epoch 799, Error: 2.1185444383249186\n",
      "Epoch 800, Error: 2.122712518854834\n",
      "Epoch 801, Error: 2.130829656498626\n",
      "Epoch 802, Error: 2.1174057460562414\n",
      "Epoch 803, Error: 2.116046790337999\n",
      "Epoch 804, Error: 2.1133376970150075\n",
      "Epoch 805, Error: 2.114858854826662\n",
      "Epoch 806, Error: 2.112421962831358\n",
      "Epoch 807, Error: 2.1133586337487578\n",
      "Epoch 808, Error: 2.1150170566234388\n",
      "Epoch 809, Error: 2.1168990802150773\n",
      "Epoch 810, Error: 2.1293828820758334\n",
      "Epoch 811, Error: 2.1393386028052506\n",
      "Epoch 812, Error: 2.121981502905157\n",
      "Epoch 813, Error: 2.125964350619021\n",
      "Epoch 814, Error: 2.116574709503802\n",
      "Epoch 815, Error: 2.115514988361568\n",
      "Epoch 816, Error: 2.1128256449660365\n",
      "Epoch 817, Error: 2.111224278747592\n",
      "Epoch 818, Error: 2.1121875155361627\n",
      "Epoch 819, Error: 2.1135291383167756\n",
      "Epoch 820, Error: 2.1132880635588354\n",
      "Epoch 821, Error: 2.111066655984133\n",
      "Epoch 822, Error: 2.110793891019255\n",
      "Epoch 823, Error: 2.110710319196094\n",
      "Epoch 824, Error: 2.111077206027711\n",
      "Epoch 825, Error: 2.1101231101293685\n",
      "Epoch 826, Error: 2.1112544258016186\n",
      "Epoch 827, Error: 2.1104201717660493\n",
      "Epoch 828, Error: 2.11657041253201\n",
      "Epoch 829, Error: 2.1187935685722143\n",
      "Epoch 830, Error: 2.1177645417270172\n",
      "Epoch 831, Error: 2.1206569148953593\n",
      "Epoch 832, Error: 2.125366012963804\n",
      "Epoch 833, Error: 2.1202704371683567\n",
      "Epoch 834, Error: 2.121070805981744\n",
      "Epoch 835, Error: 2.1169831847293947\n",
      "Epoch 836, Error: 2.113344590270418\n",
      "Epoch 837, Error: 2.111508717145384\n",
      "Epoch 838, Error: 2.111457321324081\n",
      "Epoch 839, Error: 2.1119309414909595\n",
      "Epoch 840, Error: 2.111411866591735\n",
      "Epoch 841, Error: 2.1114510512183906\n",
      "Epoch 842, Error: 2.1124172054877586\n",
      "Epoch 843, Error: 2.112968117212719\n",
      "Epoch 844, Error: 2.12194405688393\n",
      "Epoch 845, Error: 2.1223629053577087\n",
      "Epoch 846, Error: 2.1167859779924623\n",
      "Epoch 847, Error: 2.114400837639142\n",
      "Epoch 848, Error: 2.111551249558149\n",
      "Epoch 849, Error: 2.114239231338647\n",
      "Epoch 850, Error: 2.116821531949428\n",
      "Epoch 851, Error: 2.1207538620337143\n",
      "Epoch 852, Error: 2.131402615924629\n",
      "Epoch 853, Error: 2.1244081700596262\n",
      "Epoch 854, Error: 2.1157424180948485\n",
      "Epoch 855, Error: 2.1151680575227902\n",
      "Epoch 856, Error: 2.1139043536020328\n",
      "Epoch 857, Error: 2.1149977806786975\n",
      "Epoch 858, Error: 2.1194176293797446\n",
      "Epoch 859, Error: 2.1332096500783515\n",
      "Epoch 860, Error: 2.142865187519853\n",
      "Epoch 861, Error: 2.116755812760056\n",
      "Epoch 862, Error: 2.1148277597074405\n",
      "Epoch 863, Error: 2.1139017966700524\n",
      "Epoch 864, Error: 2.114143718437977\n",
      "Epoch 865, Error: 2.1131640235790172\n",
      "Epoch 866, Error: 2.111781993943254\n",
      "Epoch 867, Error: 2.109655490553554\n",
      "Epoch 868, Error: 2.114480369496268\n",
      "Epoch 869, Error: 2.1201644131983106\n",
      "Epoch 870, Error: 2.1102579151977823\n",
      "Epoch 871, Error: 2.1090170153359087\n",
      "Epoch 872, Error: 2.1109191444655138\n",
      "Epoch 873, Error: 2.1071443264774863\n",
      "Epoch 874, Error: 2.107841401569249\n",
      "Epoch 875, Error: 2.10837019802332\n",
      "Epoch 876, Error: 2.1125175118698154\n",
      "Epoch 877, Error: 2.112932677507855\n",
      "Epoch 878, Error: 2.111039993543231\n",
      "Epoch 879, Error: 2.107666588201442\n",
      "Epoch 880, Error: 2.1081014334898383\n",
      "Epoch 881, Error: 2.1085033941102203\n",
      "Epoch 882, Error: 2.108083653000434\n",
      "Epoch 883, Error: 2.1062873030356264\n",
      "Epoch 884, Error: 2.1155026478459544\n",
      "Epoch 885, Error: 2.1128868129407565\n",
      "Epoch 886, Error: 2.12427168994649\n",
      "Epoch 887, Error: 2.1349011166416223\n",
      "Epoch 888, Error: 2.1182257354348595\n",
      "Epoch 889, Error: 2.117720541745911\n",
      "Epoch 890, Error: 2.115484570331286\n",
      "Epoch 891, Error: 2.117561368268851\n",
      "Epoch 892, Error: 2.1179688685787146\n",
      "Epoch 893, Error: 2.112912625230644\n",
      "Epoch 894, Error: 2.1112255719359654\n",
      "Epoch 895, Error: 2.1137350500180387\n",
      "Epoch 896, Error: 2.1106430849936055\n",
      "Epoch 897, Error: 2.111669363404078\n",
      "Epoch 898, Error: 2.111042843775749\n",
      "Epoch 899, Error: 2.1155013475102473\n",
      "Epoch 900, Error: 2.1164985296717944\n",
      "Epoch 901, Error: 2.1186781800676715\n",
      "Epoch 902, Error: 2.1154582304946365\n",
      "Epoch 903, Error: 2.123772762900648\n",
      "Epoch 904, Error: 2.120315110028702\n",
      "Epoch 905, Error: 2.121832965411293\n",
      "Epoch 906, Error: 2.111047544592145\n",
      "Epoch 907, Error: 2.113162513165193\n",
      "Epoch 908, Error: 2.109289125615683\n",
      "Epoch 909, Error: 2.111182463541653\n",
      "Epoch 910, Error: 2.109786565071798\n",
      "Epoch 911, Error: 2.1101698788364627\n",
      "Epoch 912, Error: 2.1079768615214562\n",
      "Epoch 913, Error: 2.1073123507838103\n",
      "Epoch 914, Error: 2.107755884941323\n",
      "Epoch 915, Error: 2.1087476893293036\n",
      "Epoch 916, Error: 2.107150453595819\n",
      "Epoch 917, Error: 2.1068300350200775\n",
      "Epoch 918, Error: 2.110756229011702\n",
      "Epoch 919, Error: 2.111054688380348\n",
      "Epoch 920, Error: 2.110225726981388\n",
      "Epoch 921, Error: 2.1134018546277464\n",
      "Epoch 922, Error: 2.110274431326172\n",
      "Epoch 923, Error: 2.109282958670118\n",
      "Epoch 924, Error: 2.108358987429124\n",
      "Epoch 925, Error: 2.108830343007406\n",
      "Epoch 926, Error: 2.113268809360863\n",
      "Epoch 927, Error: 2.1126536735178894\n",
      "Epoch 928, Error: 2.1196728566201406\n",
      "Epoch 929, Error: 2.117950488406703\n",
      "Epoch 930, Error: 2.1221298141788347\n",
      "Epoch 931, Error: 2.113624470588259\n",
      "Epoch 932, Error: 2.114443437858062\n",
      "Epoch 933, Error: 2.1118748446305555\n",
      "Epoch 934, Error: 2.1144573537730214\n",
      "Epoch 935, Error: 2.1121179271577146\n",
      "Epoch 936, Error: 2.1078368310649576\n",
      "Epoch 937, Error: 2.1090428701511965\n",
      "Epoch 938, Error: 2.1138864769083536\n",
      "Epoch 939, Error: 2.10915135844352\n",
      "Epoch 940, Error: 2.10503736722673\n",
      "Epoch 941, Error: 2.1054779385156244\n",
      "Epoch 942, Error: 2.1074498247450784\n",
      "Epoch 943, Error: 2.1090343054618885\n",
      "Epoch 944, Error: 2.112771551660168\n",
      "Epoch 945, Error: 2.1064193957238526\n",
      "Epoch 946, Error: 2.1060246324566836\n",
      "Epoch 947, Error: 2.1063182129808706\n",
      "Epoch 948, Error: 2.1064103417299016\n",
      "Epoch 949, Error: 2.103958493260948\n",
      "Epoch 950, Error: 2.10367291879372\n",
      "Epoch 951, Error: 2.1042628210003524\n",
      "Epoch 952, Error: 2.103767714246546\n",
      "Epoch 953, Error: 2.1069446649429793\n",
      "Epoch 954, Error: 2.105386389240546\n",
      "Epoch 955, Error: 2.111098207802519\n",
      "Epoch 956, Error: 2.1199216453898453\n",
      "Epoch 957, Error: 2.1253651011480246\n",
      "Epoch 958, Error: 2.112837941367222\n",
      "Epoch 959, Error: 2.1146439719586465\n",
      "Epoch 960, Error: 2.1122195323607578\n",
      "Epoch 961, Error: 2.1173819243342438\n",
      "Epoch 962, Error: 2.117262244623505\n",
      "Epoch 963, Error: 2.1111567263722013\n",
      "Epoch 964, Error: 2.1092127223071233\n",
      "Epoch 965, Error: 2.1068096029905354\n",
      "Epoch 966, Error: 2.1094687647554182\n",
      "Epoch 967, Error: 2.1131141661695043\n",
      "Epoch 968, Error: 2.117806587392636\n",
      "Epoch 969, Error: 2.1200482941339427\n",
      "Epoch 970, Error: 2.1213387207842334\n",
      "Epoch 971, Error: 2.1198794019046145\n",
      "Epoch 972, Error: 2.12393248074641\n",
      "Epoch 973, Error: 2.1383898423395205\n",
      "Epoch 974, Error: 2.119133040433009\n",
      "Epoch 975, Error: 2.1161418772728235\n",
      "Epoch 976, Error: 2.111577206211761\n",
      "Epoch 977, Error: 2.1113021148240154\n",
      "Epoch 978, Error: 2.1090805136888098\n",
      "Epoch 979, Error: 2.109459341523205\n",
      "Epoch 980, Error: 2.110860184558427\n",
      "Epoch 981, Error: 2.1088744847500216\n",
      "Epoch 982, Error: 2.1060286999132867\n",
      "Epoch 983, Error: 2.105565428299296\n",
      "Epoch 984, Error: 2.111356942768768\n",
      "Epoch 985, Error: 2.1118745678901742\n",
      "Epoch 986, Error: 2.1157953522928423\n",
      "Epoch 987, Error: 2.1083475447016027\n",
      "Epoch 988, Error: 2.10543275191547\n",
      "Epoch 989, Error: 2.104010145343476\n",
      "Epoch 990, Error: 2.1047538950082387\n",
      "Epoch 991, Error: 2.106089223697048\n",
      "Epoch 992, Error: 2.103621006142074\n",
      "Epoch 993, Error: 2.1084829121937987\n",
      "Epoch 994, Error: 2.1066002883766415\n",
      "Epoch 995, Error: 2.11375264244248\n",
      "Epoch 996, Error: 2.1163712442091738\n",
      "Epoch 997, Error: 2.1138829265346133\n",
      "Epoch 998, Error: 2.1296496894252757\n",
      "Epoch 999, Error: 2.1114997196032745\n",
      "Test Accuracy: 0.22077794190054162\n"
     ]
    }
   ],
   "source": [
    "#Cortar en features y labales\n",
    "channel_data_train_samples = channel_data.shape[0]\n",
    "features = channel_data  # Features for training\n",
    "\n",
    "features = cp.array(features)\n",
    "\n",
    "print(channel_data.shape)\n",
    "print(features.shape )\n",
    "print(labels.shape)\n",
    "\n",
    "X_train = cp.array(features)\n",
    "\n",
    "num_classes = 10\n",
    "input_size = 12\n",
    "hidden_layers = [256,256]  # Tamaños de las capas ocultas\n",
    "output_size = 10\n",
    "layer_sizes = [input_size] + hidden_layers + [output_size]\n",
    "epochs = 1000\n",
    "learning_rate = 0.1\n",
    "dropout_rate = 0.2\n",
    "\n",
    "model = MultiLayerNetwork(layer_sizes)\n",
    "errors = model.train(X_train, y_train, epochs, learning_rate)\n",
    "#Evaluar\n",
    "predictions = model.predict(X_train)\n",
    "\n",
    "accuracy = cp.mean(predictions.argmax(axis=1) == y_train)\n",
    "print(f'Test Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UTIL\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data prep pero cortando 20% para test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtener datos (estoy usando pd porque anda considerablemente más rápido que np)\n",
    "train_data = pd.read_csv(r'C:/Users/kueru/Documents/VSCode/semestre_9/Deep_Learning/T2/train_data_2.csv')\n",
    "train_data = train_data.to_numpy()\n",
    "\n",
    "#Cortar en features y labales\n",
    "train_samples = train_data.shape[0]\n",
    "features = train_data[:train_samples, :-1]  # Features for training\n",
    "labels = train_data[:train_samples, -1]   # Labels for training\n",
    "\n",
    "features = cp.array(features)\n",
    "labels = cp.array(labels, ndmin=2)\n",
    "labels = labels.reshape(-1, 1)  # Reshape to (299, 1)\n",
    "\n",
    "print(train_data.shape)\n",
    "print(features.shape )\n",
    "print(labels.shape)\n",
    "\n",
    "\n",
    "indices = cp.arange(train_samples)\n",
    "\n",
    "#cortar 20% test \n",
    "test_size = 0.2\n",
    "test_samples = int(test_size * train_samples)\n",
    "train_indices, test_indices = indices[test_samples:], indices[:test_samples]\n",
    "\n",
    "X_train, X_test = features[train_indices], features[test_indices]\n",
    "y_train, y_test = labels[train_indices], labels[test_indices]\n",
    "\n",
    "train_indices = cp.array(train_indices)\n",
    "test_indices = cp.array(test_indices)\n",
    "X_train = cp.array(X_train)\n",
    "X_test = cp.array(X_test)\n",
    "y_train = cp.array(y_train)\n",
    "y_test = cp.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#Obtener datos (estoy usando pd porque anda considerablemente más rápido que np)\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m train_data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mC:/Users/kueru/Documents/VSCode/semestre_9/Deep_Learning/T2/train_data.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m train_data \u001b[38;5;241m=\u001b[39m train_data\u001b[38;5;241m.\u001b[39mto_numpy()\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m#Cortar en features y labales\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\kueru\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\kueru\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:625\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[1;32m--> 625\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mparser\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    626\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mreturn\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\kueru\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1996\u001b[0m, in \u001b[0;36mTextFileReader.__exit__\u001b[1;34m(self, exc_type, exc_value, traceback)\u001b[0m\n\u001b[0;32m   1990\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__exit__\u001b[39m(\n\u001b[0;32m   1991\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1992\u001b[0m     exc_type: \u001b[38;5;28mtype\u001b[39m[\u001b[38;5;167;01mBaseException\u001b[39;00m] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1993\u001b[0m     exc_value: \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1994\u001b[0m     traceback: TracebackType \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1995\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1996\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclose\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\kueru\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1622\u001b[0m, in \u001b[0;36mTextFileReader.close\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1619\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1620\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n\u001b[1;32m-> 1622\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mclose\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1623\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1624\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mclose()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Obtener datos (estoy usando pd porque anda considerablemente más rápido que np)\n",
    "train_data = pd.read_csv(r'C:/Users/kueru/Documents/VSCode/semestre_9/Deep_Learning/T2/train_data.csv')\n",
    "train_data = train_data.to_numpy()\n",
    "    \n",
    "#Cortar en features y labales\n",
    "train_samples = train_data.shape[0]\n",
    "features = train_data[:train_samples, 1:-1]  # Features for training\n",
    "labels = train_data[:train_samples, -1]   # Labels for training\n",
    "\n",
    "# Reduce pixel values\n",
    "features = features / 255.0 \n",
    "# flatten the label values\n",
    "labels = labels.flatten()\n",
    "\n",
    "features = cp.array(features)\n",
    "labels = cp.array(labels, ndmin=2)\n",
    "labels = labels.reshape(-1, 1)  # Reshape to (299, 1)\n",
    "\n",
    "print(train_data.shape)\n",
    "print(features.shape )\n",
    "print(labels.shape)\n",
    "\n",
    "\n",
    "indices = cp.arange(train_samples)\n",
    "\n",
    "\n",
    "X_train = cp.array(features)\n",
    "\n",
    "num_classes = 10\n",
    "input_size = 3072\n",
    "hidden_layers = [100, 100]  # Tamaños de las capas ocultas\n",
    "output_size = 10\n",
    "layer_sizes = [input_size] + hidden_layers + [output_size]\n",
    "\n",
    "model = MultiLayerNetwork(layer_sizes)\n",
    "epochs = 1\n",
    "learning_rate = 0.001\n",
    "\n",
    "errors = model.train(X_train, y_train, epochs, learning_rate, 2.5)\n",
    "print(errors)\n",
    "#Evaluar\n",
    "predictions = model.predict(X_train)\n",
    "accuracy = cp.mean(predictions.argmax(axis=1) == y_train)\n",
    "print(f'Test Accuracy: {accuracy}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
